{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNST_CIFAR10_AUG.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/raviteja8484/ML/blob/master/4Baccuracy87(8).ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "K70hAckqg0EA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "20dab3ee-5540-4e57-a199-730c0f0c8fa2"
      },
      "cell_type": "code",
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "wVIx_KIigxPV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UNHw6luQg3gc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dsO_yGxcg5D8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "l = 12\n",
        "num_filter = 12\n",
        "compression = 0.5\n",
        "dropout_rate = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mB7o3zu1g6eT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load CIFAR10 Data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ee-sge5Kg7vr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Dense Block\n",
        "def add_denseblock(input, num_filter = 64, dropout_rate = 0.3):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l):\n",
        "        BatchNorm = BatchNormalization()(temp)\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OOP6IPsGhBwb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def add_transition(input, num_filter = 64, dropout_rate = 0.3):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0RaKFpubhDIC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = Flatten()(AvgPooling)\n",
        "    output = Dense(num_classes, activation='softmax')(flat)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_7eyYVKXzjfs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "anPCpQWhhGb7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_filter = 64\n",
        "dropout_rate = 0.3\n",
        "l = 12\n",
        "input = Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block = add_denseblock(Third_Transition,  num_filter, dropout_rate)\n",
        "output = output_layer(Last_Block)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pm6_Vss6zs8F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filepath=\"weights.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1kFh7pdxhNtT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9744
        },
        "outputId": "1a2477d8-2aa0-46cd-ad25-8848afe1bd18"
      },
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 32, 32, 64)   1728        input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 32, 32, 64)   256         conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 32, 32, 64)   0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 32, 32, 32)   18432       activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_103 (Dropout)           (None, 32, 32, 32)   0           conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_97 (Concatenate)    (None, 32, 32, 96)   0           conv2d_105[0][0]                 \n",
            "                                                                 dropout_103[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 32, 32, 96)   384         concatenate_97[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 32, 32, 96)   0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 32, 32, 32)   27648       activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_104 (Dropout)           (None, 32, 32, 32)   0           conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_98 (Concatenate)    (None, 32, 32, 128)  0           concatenate_97[0][0]             \n",
            "                                                                 dropout_104[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 32, 32, 128)  512         concatenate_98[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 32, 32, 128)  0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 32, 32, 32)   36864       activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_105 (Dropout)           (None, 32, 32, 32)   0           conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_99 (Concatenate)    (None, 32, 32, 160)  0           concatenate_98[0][0]             \n",
            "                                                                 dropout_105[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 32, 32, 160)  640         concatenate_99[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 32, 32, 160)  0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 32, 32, 32)   46080       activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_106 (Dropout)           (None, 32, 32, 32)   0           conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_100 (Concatenate)   (None, 32, 32, 192)  0           concatenate_99[0][0]             \n",
            "                                                                 dropout_106[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 32, 32, 192)  768         concatenate_100[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 32, 32, 192)  0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 32, 32, 32)   55296       activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_107 (Dropout)           (None, 32, 32, 32)   0           conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_101 (Concatenate)   (None, 32, 32, 224)  0           concatenate_100[0][0]            \n",
            "                                                                 dropout_107[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 32, 32, 224)  896         concatenate_101[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 32, 32, 224)  0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 32, 32, 32)   64512       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_108 (Dropout)           (None, 32, 32, 32)   0           conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_102 (Concatenate)   (None, 32, 32, 256)  0           concatenate_101[0][0]            \n",
            "                                                                 dropout_108[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 32, 32, 256)  1024        concatenate_102[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 32, 32, 256)  0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 32, 32, 32)   73728       activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_109 (Dropout)           (None, 32, 32, 32)   0           conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_103 (Concatenate)   (None, 32, 32, 288)  0           concatenate_102[0][0]            \n",
            "                                                                 dropout_109[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 32, 32, 288)  1152        concatenate_103[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 32, 32, 288)  0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 32, 32, 32)   82944       activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_110 (Dropout)           (None, 32, 32, 32)   0           conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_104 (Concatenate)   (None, 32, 32, 320)  0           concatenate_103[0][0]            \n",
            "                                                                 dropout_110[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 32, 32, 320)  1280        concatenate_104[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 32, 32, 320)  0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 32, 32, 32)   92160       activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_111 (Dropout)           (None, 32, 32, 32)   0           conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_105 (Concatenate)   (None, 32, 32, 352)  0           concatenate_104[0][0]            \n",
            "                                                                 dropout_111[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 32, 32, 352)  1408        concatenate_105[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 32, 32, 352)  0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 32, 32, 32)   101376      activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_112 (Dropout)           (None, 32, 32, 32)   0           conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_106 (Concatenate)   (None, 32, 32, 384)  0           concatenate_105[0][0]            \n",
            "                                                                 dropout_112[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 32, 32, 384)  1536        concatenate_106[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 32, 32, 384)  0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 32, 32, 32)   110592      activation_115[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_113 (Dropout)           (None, 32, 32, 32)   0           conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_107 (Concatenate)   (None, 32, 32, 416)  0           concatenate_106[0][0]            \n",
            "                                                                 dropout_113[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 32, 32, 416)  1664        concatenate_107[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 32, 32, 416)  0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 32, 32, 32)   119808      activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_114 (Dropout)           (None, 32, 32, 32)   0           conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_108 (Concatenate)   (None, 32, 32, 448)  0           concatenate_107[0][0]            \n",
            "                                                                 dropout_114[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 32, 32, 448)  1792        concatenate_108[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 32, 32, 448)  0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 32, 32, 32)   14336       activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_115 (Dropout)           (None, 32, 32, 32)   0           conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 16, 16, 32)   0           dropout_115[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 16, 16, 32)   128         average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 16, 16, 32)   0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 16, 16, 32)   9216        activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_116 (Dropout)           (None, 16, 16, 32)   0           conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_109 (Concatenate)   (None, 16, 16, 64)   0           average_pooling2d_9[0][0]        \n",
            "                                                                 dropout_116[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 16, 16, 64)   256         concatenate_109[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 16, 16, 64)   0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 16, 16, 32)   18432       activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_117 (Dropout)           (None, 16, 16, 32)   0           conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_110 (Concatenate)   (None, 16, 16, 96)   0           concatenate_109[0][0]            \n",
            "                                                                 dropout_117[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 16, 16, 96)   384         concatenate_110[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 16, 16, 96)   0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 16, 16, 32)   27648       activation_120[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_118 (Dropout)           (None, 16, 16, 32)   0           conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_111 (Concatenate)   (None, 16, 16, 128)  0           concatenate_110[0][0]            \n",
            "                                                                 dropout_118[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 16, 16, 128)  512         concatenate_111[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 16, 16, 128)  0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 16, 16, 32)   36864       activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_119 (Dropout)           (None, 16, 16, 32)   0           conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_112 (Concatenate)   (None, 16, 16, 160)  0           concatenate_111[0][0]            \n",
            "                                                                 dropout_119[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 16, 16, 160)  640         concatenate_112[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 16, 16, 160)  0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 16, 16, 32)   46080       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_120 (Dropout)           (None, 16, 16, 32)   0           conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_113 (Concatenate)   (None, 16, 16, 192)  0           concatenate_112[0][0]            \n",
            "                                                                 dropout_120[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 16, 16, 192)  768         concatenate_113[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 16, 16, 192)  0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 16, 16, 32)   55296       activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_121 (Dropout)           (None, 16, 16, 32)   0           conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_114 (Concatenate)   (None, 16, 16, 224)  0           concatenate_113[0][0]            \n",
            "                                                                 dropout_121[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 16, 16, 224)  896         concatenate_114[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 16, 16, 224)  0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 16, 16, 32)   64512       activation_124[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_122 (Dropout)           (None, 16, 16, 32)   0           conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_115 (Concatenate)   (None, 16, 16, 256)  0           concatenate_114[0][0]            \n",
            "                                                                 dropout_122[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 16, 16, 256)  1024        concatenate_115[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 16, 16, 256)  0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 16, 16, 32)   73728       activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_123 (Dropout)           (None, 16, 16, 32)   0           conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_116 (Concatenate)   (None, 16, 16, 288)  0           concatenate_115[0][0]            \n",
            "                                                                 dropout_123[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 16, 16, 288)  1152        concatenate_116[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 16, 16, 288)  0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 16, 16, 32)   82944       activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_124 (Dropout)           (None, 16, 16, 32)   0           conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_117 (Concatenate)   (None, 16, 16, 320)  0           concatenate_116[0][0]            \n",
            "                                                                 dropout_124[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 16, 16, 320)  1280        concatenate_117[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 16, 16, 320)  0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 16, 16, 32)   92160       activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_125 (Dropout)           (None, 16, 16, 32)   0           conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_118 (Concatenate)   (None, 16, 16, 352)  0           concatenate_117[0][0]            \n",
            "                                                                 dropout_125[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 16, 16, 352)  1408        concatenate_118[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 16, 16, 352)  0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 16, 16, 32)   101376      activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_126 (Dropout)           (None, 16, 16, 32)   0           conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_119 (Concatenate)   (None, 16, 16, 384)  0           concatenate_118[0][0]            \n",
            "                                                                 dropout_126[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 16, 16, 384)  1536        concatenate_119[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 16, 16, 384)  0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 16, 16, 32)   110592      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_127 (Dropout)           (None, 16, 16, 32)   0           conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_120 (Concatenate)   (None, 16, 16, 416)  0           concatenate_119[0][0]            \n",
            "                                                                 dropout_127[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 16, 16, 416)  1664        concatenate_120[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 16, 16, 416)  0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 16, 16, 32)   13312       activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_128 (Dropout)           (None, 16, 16, 32)   0           conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_10 (AveragePo (None, 8, 8, 32)     0           dropout_128[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 8, 8, 32)     128         average_pooling2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 8, 8, 32)     0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 8, 8, 32)     9216        activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_129 (Dropout)           (None, 8, 8, 32)     0           conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_121 (Concatenate)   (None, 8, 8, 64)     0           average_pooling2d_10[0][0]       \n",
            "                                                                 dropout_129[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 8, 8, 64)     256         concatenate_121[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 8, 8, 64)     0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 8, 8, 32)     18432       activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_130 (Dropout)           (None, 8, 8, 32)     0           conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_122 (Concatenate)   (None, 8, 8, 96)     0           concatenate_121[0][0]            \n",
            "                                                                 dropout_130[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 8, 8, 96)     384         concatenate_122[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 8, 8, 96)     0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 8, 8, 32)     27648       activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_131 (Dropout)           (None, 8, 8, 32)     0           conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_123 (Concatenate)   (None, 8, 8, 128)    0           concatenate_122[0][0]            \n",
            "                                                                 dropout_131[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 8, 8, 128)    512         concatenate_123[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 8, 8, 128)    0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 8, 8, 32)     36864       activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_132 (Dropout)           (None, 8, 8, 32)     0           conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_124 (Concatenate)   (None, 8, 8, 160)    0           concatenate_123[0][0]            \n",
            "                                                                 dropout_132[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 8, 8, 160)    640         concatenate_124[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 8, 8, 160)    0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 8, 8, 32)     46080       activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_133 (Dropout)           (None, 8, 8, 32)     0           conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_125 (Concatenate)   (None, 8, 8, 192)    0           concatenate_124[0][0]            \n",
            "                                                                 dropout_133[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 8, 8, 192)    768         concatenate_125[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 8, 8, 192)    0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 8, 8, 32)     55296       activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_134 (Dropout)           (None, 8, 8, 32)     0           conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_126 (Concatenate)   (None, 8, 8, 224)    0           concatenate_125[0][0]            \n",
            "                                                                 dropout_134[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 8, 8, 224)    896         concatenate_126[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 8, 8, 224)    0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 8, 8, 32)     64512       activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_135 (Dropout)           (None, 8, 8, 32)     0           conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_127 (Concatenate)   (None, 8, 8, 256)    0           concatenate_126[0][0]            \n",
            "                                                                 dropout_135[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 8, 8, 256)    1024        concatenate_127[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 8, 8, 256)    0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 8, 8, 32)     73728       activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_136 (Dropout)           (None, 8, 8, 32)     0           conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_128 (Concatenate)   (None, 8, 8, 288)    0           concatenate_127[0][0]            \n",
            "                                                                 dropout_136[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 8, 8, 288)    1152        concatenate_128[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 8, 8, 288)    0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 8, 8, 32)     82944       activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_137 (Dropout)           (None, 8, 8, 32)     0           conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_129 (Concatenate)   (None, 8, 8, 320)    0           concatenate_128[0][0]            \n",
            "                                                                 dropout_137[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 8, 8, 320)    1280        concatenate_129[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 8, 8, 320)    0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 8, 8, 32)     92160       activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_138 (Dropout)           (None, 8, 8, 32)     0           conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_130 (Concatenate)   (None, 8, 8, 352)    0           concatenate_129[0][0]            \n",
            "                                                                 dropout_138[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 8, 8, 352)    1408        concatenate_130[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 8, 8, 352)    0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 8, 8, 32)     101376      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_139 (Dropout)           (None, 8, 8, 32)     0           conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_131 (Concatenate)   (None, 8, 8, 384)    0           concatenate_130[0][0]            \n",
            "                                                                 dropout_139[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 8, 8, 384)    1536        concatenate_131[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 8, 8, 384)    0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 8, 8, 32)     110592      activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_140 (Dropout)           (None, 8, 8, 32)     0           conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_132 (Concatenate)   (None, 8, 8, 416)    0           concatenate_131[0][0]            \n",
            "                                                                 dropout_140[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 8, 8, 416)    1664        concatenate_132[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 8, 8, 416)    0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 8, 8, 32)     13312       activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_141 (Dropout)           (None, 8, 8, 32)     0           conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_11 (AveragePo (None, 4, 4, 32)     0           dropout_141[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 4, 4, 32)     128         average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 4, 4, 32)     0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 4, 4, 32)     9216        activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_142 (Dropout)           (None, 4, 4, 32)     0           conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_133 (Concatenate)   (None, 4, 4, 64)     0           average_pooling2d_11[0][0]       \n",
            "                                                                 dropout_142[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 4, 4, 64)     256         concatenate_133[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 4, 4, 64)     0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 4, 4, 32)     18432       activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_143 (Dropout)           (None, 4, 4, 32)     0           conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_134 (Concatenate)   (None, 4, 4, 96)     0           concatenate_133[0][0]            \n",
            "                                                                 dropout_143[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 4, 4, 96)     384         concatenate_134[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 4, 4, 96)     0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 4, 4, 32)     27648       activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_144 (Dropout)           (None, 4, 4, 32)     0           conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_135 (Concatenate)   (None, 4, 4, 128)    0           concatenate_134[0][0]            \n",
            "                                                                 dropout_144[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 4, 4, 128)    512         concatenate_135[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 4, 4, 128)    0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 4, 4, 32)     36864       activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_145 (Dropout)           (None, 4, 4, 32)     0           conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_136 (Concatenate)   (None, 4, 4, 160)    0           concatenate_135[0][0]            \n",
            "                                                                 dropout_145[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 4, 4, 160)    640         concatenate_136[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 4, 4, 160)    0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 4, 4, 32)     46080       activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_146 (Dropout)           (None, 4, 4, 32)     0           conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_137 (Concatenate)   (None, 4, 4, 192)    0           concatenate_136[0][0]            \n",
            "                                                                 dropout_146[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 4, 4, 192)    768         concatenate_137[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 4, 4, 192)    0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 4, 4, 32)     55296       activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_147 (Dropout)           (None, 4, 4, 32)     0           conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_138 (Concatenate)   (None, 4, 4, 224)    0           concatenate_137[0][0]            \n",
            "                                                                 dropout_147[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 4, 4, 224)    896         concatenate_138[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 4, 4, 224)    0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 4, 4, 32)     64512       activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_148 (Dropout)           (None, 4, 4, 32)     0           conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_139 (Concatenate)   (None, 4, 4, 256)    0           concatenate_138[0][0]            \n",
            "                                                                 dropout_148[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 4, 4, 256)    1024        concatenate_139[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 4, 4, 256)    0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 4, 4, 32)     73728       activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_149 (Dropout)           (None, 4, 4, 32)     0           conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_140 (Concatenate)   (None, 4, 4, 288)    0           concatenate_139[0][0]            \n",
            "                                                                 dropout_149[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 4, 4, 288)    1152        concatenate_140[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 4, 4, 288)    0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 4, 4, 32)     82944       activation_152[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_150 (Dropout)           (None, 4, 4, 32)     0           conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_141 (Concatenate)   (None, 4, 4, 320)    0           concatenate_140[0][0]            \n",
            "                                                                 dropout_150[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 4, 4, 320)    1280        concatenate_141[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 4, 4, 320)    0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 4, 4, 32)     92160       activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_151 (Dropout)           (None, 4, 4, 32)     0           conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_142 (Concatenate)   (None, 4, 4, 352)    0           concatenate_141[0][0]            \n",
            "                                                                 dropout_151[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 4, 4, 352)    1408        concatenate_142[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 4, 4, 352)    0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 4, 4, 32)     101376      activation_154[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_152 (Dropout)           (None, 4, 4, 32)     0           conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_143 (Concatenate)   (None, 4, 4, 384)    0           concatenate_142[0][0]            \n",
            "                                                                 dropout_152[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 4, 4, 384)    1536        concatenate_143[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 4, 4, 384)    0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 4, 4, 32)     110592      activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_153 (Dropout)           (None, 4, 4, 32)     0           conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_144 (Concatenate)   (None, 4, 4, 416)    0           concatenate_143[0][0]            \n",
            "                                                                 dropout_153[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 4, 4, 416)    1664        concatenate_144[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 4, 4, 416)    0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, 2, 2, 416)    0           activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 1664)         0           average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 10)           16650       flatten_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 3,093,578\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Trainable params: 3,069,450\n",
            "Non-trainable params: 24,128\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b4XOsW3ahSkL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# determine Loss function and Optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "crhGk7kEhXAz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2439
        },
        "outputId": "4a9b6313-6060-4d24-bd65-8a637fba9e72"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    callbacks=callbacks_list,\n",
        "                    validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 520s 10ms/step - loss: 1.4869 - acc: 0.4544 - val_loss: 2.2372 - val_acc: 0.4011\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.40110, saving model to weights.best.hdf5\n",
            "Epoch 2/50\n",
            "14464/50000 [=======>......................] - ETA: 5:27 - loss: 1.1241 - acc: 0.5921"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 495s 10ms/step - loss: 1.0339 - acc: 0.6291 - val_loss: 1.5964 - val_acc: 0.5368\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.40110 to 0.53680, saving model to weights.best.hdf5\n",
            "Epoch 3/50\n",
            "30848/50000 [=================>............] - ETA: 2:55 - loss: 0.8650 - acc: 0.6888"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 495s 10ms/step - loss: 0.8388 - acc: 0.6999 - val_loss: 1.8386 - val_acc: 0.5529\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.53680 to 0.55290, saving model to weights.best.hdf5\n",
            "Epoch 4/50\n",
            "35328/50000 [====================>.........] - ETA: 2:14 - loss: 0.7275 - acc: 0.7417"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 495s 10ms/step - loss: 0.7147 - acc: 0.7468 - val_loss: 1.7029 - val_acc: 0.5800\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.55290 to 0.58000, saving model to weights.best.hdf5\n",
            "Epoch 5/50\n",
            "36480/50000 [====================>.........] - ETA: 2:04 - loss: 0.6331 - acc: 0.7759"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 494s 10ms/step - loss: 0.6304 - acc: 0.7778 - val_loss: 0.9895 - val_acc: 0.7130\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.58000 to 0.71300, saving model to weights.best.hdf5\n",
            "Epoch 6/50\n",
            "36864/50000 [=====================>........] - ETA: 2:00 - loss: 0.5638 - acc: 0.8038"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 495s 10ms/step - loss: 0.5650 - acc: 0.8033 - val_loss: 0.7783 - val_acc: 0.7659\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.71300 to 0.76590, saving model to weights.best.hdf5\n",
            "Epoch 7/50\n",
            "36864/50000 [=====================>........] - ETA: 2:00 - loss: 0.5202 - acc: 0.8180"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 494s 10ms/step - loss: 0.5232 - acc: 0.8175 - val_loss: 1.1160 - val_acc: 0.7172\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.76590\n",
            "Epoch 8/50\n",
            "42240/50000 [========================>.....] - ETA: 1:11 - loss: 0.4793 - acc: 0.8328"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 494s 10ms/step - loss: 0.4763 - acc: 0.8340 - val_loss: 0.9671 - val_acc: 0.7329\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.76590\n",
            "Epoch 9/50\n",
            "43904/50000 [=========================>....] - ETA: 55s - loss: 0.4448 - acc: 0.8444"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 495s 10ms/step - loss: 0.4454 - acc: 0.8442 - val_loss: 1.1237 - val_acc: 0.7000\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.76590\n",
            "Epoch 10/50\n",
            "44288/50000 [=========================>....] - ETA: 52s - loss: 0.4200 - acc: 0.8529"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 494s 10ms/step - loss: 0.4193 - acc: 0.8534 - val_loss: 0.8029 - val_acc: 0.7789\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.76590 to 0.77890, saving model to weights.best.hdf5\n",
            "Epoch 11/50\n",
            "38784/50000 [======================>.......] - ETA: 1:44 - loss: 0.3889 - acc: 0.8631"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 501s 10ms/step - loss: 0.3910 - acc: 0.8628 - val_loss: 1.0971 - val_acc: 0.7202\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.77890\n",
            "Epoch 12/50\n",
            "42752/50000 [========================>.....] - ETA: 1:07 - loss: 0.3693 - acc: 0.8696"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 502s 10ms/step - loss: 0.3706 - acc: 0.8693 - val_loss: 0.7044 - val_acc: 0.7986\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.77890 to 0.79860, saving model to weights.best.hdf5\n",
            "Epoch 13/50\n",
            "38400/50000 [======================>.......] - ETA: 1:48 - loss: 0.3420 - acc: 0.8803"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 502s 10ms/step - loss: 0.3438 - acc: 0.8800 - val_loss: 0.8857 - val_acc: 0.7782\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.79860\n",
            "Epoch 14/50\n",
            "42752/50000 [========================>.....] - ETA: 1:07 - loss: 0.3279 - acc: 0.8827"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 502s 10ms/step - loss: 0.3275 - acc: 0.8832 - val_loss: 1.3190 - val_acc: 0.7034\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.79860\n",
            "Epoch 15/50\n",
            "43904/50000 [=========================>....] - ETA: 56s - loss: 0.3032 - acc: 0.8938"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 502s 10ms/step - loss: 0.3082 - acc: 0.8918 - val_loss: 0.7243 - val_acc: 0.8162\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.79860 to 0.81620, saving model to weights.best.hdf5\n",
            "Epoch 16/50\n",
            "38656/50000 [======================>.......] - ETA: 1:45 - loss: 0.2921 - acc: 0.8984"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 500s 10ms/step - loss: 0.2928 - acc: 0.8975 - val_loss: 0.8400 - val_acc: 0.7943\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.81620\n",
            "Epoch 17/50\n",
            "42624/50000 [========================>.....] - ETA: 1:08 - loss: 0.2731 - acc: 0.9043"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 497s 10ms/step - loss: 0.2758 - acc: 0.9033 - val_loss: 0.5194 - val_acc: 0.8448\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.81620 to 0.84480, saving model to weights.best.hdf5\n",
            "Epoch 18/50\n",
            "38400/50000 [======================>.......] - ETA: 1:47 - loss: 0.2645 - acc: 0.9066"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 497s 10ms/step - loss: 0.2642 - acc: 0.9065 - val_loss: 0.6177 - val_acc: 0.8468\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.84480 to 0.84680, saving model to weights.best.hdf5\n",
            "Epoch 19/50\n",
            "37248/50000 [=====================>........] - ETA: 1:57 - loss: 0.2401 - acc: 0.9129"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 499s 10ms/step - loss: 0.2489 - acc: 0.9106 - val_loss: 1.2002 - val_acc: 0.7609\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.84680\n",
            "Epoch 20/50\n",
            "42240/50000 [========================>.....] - ETA: 1:11 - loss: 0.2345 - acc: 0.9185"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 499s 10ms/step - loss: 0.2381 - acc: 0.9176 - val_loss: 0.6067 - val_acc: 0.8571\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.84680 to 0.85710, saving model to weights.best.hdf5\n",
            "Epoch 21/50\n",
            "38272/50000 [=====================>........] - ETA: 1:48 - loss: 0.2205 - acc: 0.9232"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 500s 10ms/step - loss: 0.2268 - acc: 0.9206 - val_loss: 0.6407 - val_acc: 0.8422\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.85710\n",
            "Epoch 22/50\n",
            "42624/50000 [========================>.....] - ETA: 1:08 - loss: 0.2146 - acc: 0.9243"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 500s 10ms/step - loss: 0.2156 - acc: 0.9241 - val_loss: 0.6616 - val_acc: 0.8447\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.85710\n",
            "Epoch 23/50\n",
            "43904/50000 [=========================>....] - ETA: 56s - loss: 0.2074 - acc: 0.9264"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 499s 10ms/step - loss: 0.2077 - acc: 0.9264 - val_loss: 0.5989 - val_acc: 0.8546\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.85710\n",
            "Epoch 24/50\n",
            "44288/50000 [=========================>....] - ETA: 52s - loss: 0.1930 - acc: 0.9309"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 497s 10ms/step - loss: 0.1950 - acc: 0.9302 - val_loss: 0.6485 - val_acc: 0.8463\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.85710\n",
            "Epoch 25/50\n",
            "44416/50000 [=========================>....] - ETA: 51s - loss: 0.1891 - acc: 0.9334"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 498s 10ms/step - loss: 0.1899 - acc: 0.9329 - val_loss: 0.7873 - val_acc: 0.8268\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.85710\n",
            "Epoch 26/50\n",
            "44416/50000 [=========================>....] - ETA: 51s - loss: 0.1748 - acc: 0.9377"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 497s 10ms/step - loss: 0.1756 - acc: 0.9376 - val_loss: 0.6997 - val_acc: 0.8439\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.85710\n",
            "Epoch 27/50\n",
            "44416/50000 [=========================>....] - ETA: 51s - loss: 0.1712 - acc: 0.9371"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 500s 10ms/step - loss: 0.1738 - acc: 0.9364 - val_loss: 0.6329 - val_acc: 0.8568\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.85710\n",
            "Epoch 28/50\n",
            "44416/50000 [=========================>....] - ETA: 51s - loss: 0.1637 - acc: 0.9413"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 500s 10ms/step - loss: 0.1649 - acc: 0.9413 - val_loss: 0.9651 - val_acc: 0.8172\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.85710\n",
            "Epoch 29/50\n",
            "44416/50000 [=========================>....] - ETA: 51s - loss: 0.1562 - acc: 0.9446"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 500s 10ms/step - loss: 0.1578 - acc: 0.9436 - val_loss: 0.6727 - val_acc: 0.8464\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.85710\n",
            "Epoch 30/50\n",
            "44416/50000 [=========================>....] - ETA: 51s - loss: 0.1525 - acc: 0.9461"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 500s 10ms/step - loss: 0.1539 - acc: 0.9456 - val_loss: 0.8658 - val_acc: 0.8220\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.85710\n",
            "Epoch 31/50\n",
            "44416/50000 [=========================>....] - ETA: 51s - loss: 0.1468 - acc: 0.9480"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 499s 10ms/step - loss: 0.1468 - acc: 0.9476 - val_loss: 0.6910 - val_acc: 0.8508\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.85710\n",
            "Epoch 32/50\n",
            "44416/50000 [=========================>....] - ETA: 51s - loss: 0.1374 - acc: 0.9500"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 498s 10ms/step - loss: 0.1397 - acc: 0.9495 - val_loss: 0.5931 - val_acc: 0.8644\n",
            "\n",
            "Epoch 00032: val_acc improved from 0.85710 to 0.86440, saving model to weights.best.hdf5\n",
            "Epoch 33/50\n",
            "38784/50000 [======================>.......] - ETA: 1:43 - loss: 0.1327 - acc: 0.9525"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 498s 10ms/step - loss: 0.1334 - acc: 0.9521 - val_loss: 0.7915 - val_acc: 0.8432\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.86440\n",
            "Epoch 34/50\n",
            "42752/50000 [========================>.....] - ETA: 1:06 - loss: 0.1317 - acc: 0.9539"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 498s 10ms/step - loss: 0.1320 - acc: 0.9537 - val_loss: 0.6998 - val_acc: 0.8424\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.86440\n",
            "Epoch 35/50\n",
            "43904/50000 [=========================>....] - ETA: 56s - loss: 0.1197 - acc: 0.9562"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 498s 10ms/step - loss: 0.1213 - acc: 0.9555 - val_loss: 0.5730 - val_acc: 0.8783\n",
            "\n",
            "Epoch 00035: val_acc improved from 0.86440 to 0.87830, saving model to weights.best.hdf5\n",
            "Epoch 36/50\n",
            "38656/50000 [======================>.......] - ETA: 1:44 - loss: 0.1163 - acc: 0.9572"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "40192/50000 [=======================>......] - ETA: 1:30 - loss: 0.1178 - acc: 0.9565"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZcWydmIVhZGr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a0345aa5-79ff-4e56-eb94-50437b43c4fe"
      },
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 13s 1ms/step\n",
            "Test loss: 0.7949684534072876\n",
            "Test accuracy: 0.7609\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UE3lF6EH1r_L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "92df862c-76a7-4a02-9533-6c164bc5984d"
      },
      "cell_type": "code",
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "model.save_weights(\"DNST_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ai-yZ2ED5AK1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('DNST_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Og56VCRh5j8V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}