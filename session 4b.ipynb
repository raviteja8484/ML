{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"session 4b","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"q-ks31Ar8VAM","colab_type":"text"},"cell_type":"markdown","source":[""]},{"metadata":{"id":"_siNGSyRgCJy","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# https://keras.io/\n","!pip install -q keras\n","import keras"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CBx1phceq_Pb","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"grWlOCQ4gLhl","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import keras\n","from keras.datasets import cifar10\n","from keras.models import Model, Sequential\n","from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n","from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n","from keras.layers import Concatenate\n","from keras.optimizers import Adam"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kiqHWByDgO5i","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n","# backend\n","import tensorflow as tf\n","from keras import backend as k\n","\n","# Don't pre-allocate memory; allocate as-needed\n","config = tf.ConfigProto()\n","config.gpu_options.allow_growth = True\n","\n","# Create a session with the above options specified.\n","k.tensorflow_backend.set_session(tf.Session(config=config))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XQ19SVBxgZgN","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Hyperparameters\n","# Here I changed the no of filters as by compressing the no of filters will be decreased again, so we took more no of filters.\n","# No of layers we changed the to half\n","num_classes = 10\n","epochs = 50\n","l = 20\n","num_filter = 64\n","compression = 0.5\n","dropout_rate = 0.3"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DBiDu3-dgfDD","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":54},"outputId":"7afd4a3f-0c13-4735-ee81-c824a2e10c34","executionInfo":{"status":"ok","timestamp":1527523922500,"user_tz":-330,"elapsed":58108,"user":{"displayName":"pravallika datascience","photoUrl":"//lh5.googleusercontent.com/-kbOlHQuPOOc/AAAAAAAAAAI/AAAAAAAAAAc/-NbF7DfDFPE/s50-c-k-no/photo.jpg","userId":"114842818830057023722"}}},"cell_type":"code","source":["# Load CIFAR10 Data\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n","\n","# convert to one hot encoing \n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","145022976/170498071 [========================>.....] - ETA: 7s"],"name":"stdout"},{"output_type":"stream","text":["170500096/170498071 [==============================] - 54s 0us/step\n"],"name":"stdout"}]},{"metadata":{"id":"eabzZl5i9338","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Dense Block\n","def add_denseblock(input, num_filter = 64, dropout_rate = 0.3):\n","    global compression\n","    temp = input\n","    for _ in range(l):\n","        BatchNorm = BatchNormalization()(temp)\n","        relu = Activation('relu')(BatchNorm)\n","        Conv2D_3_3 = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n","        if dropout_rate>0:\n","          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n","        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n","        \n","        temp = concat\n","        \n","    return temp"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OOP6IPsGhBwb","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def add_transition(input, num_filter = 64, dropout_rate = 0.3):\n","    global compression\n","    BatchNorm = BatchNormalization()(input)\n","    relu = Activation('relu')(BatchNorm)\n","    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n","    if dropout_rate>0:\n","      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n","    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n","    \n","    return avg"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Gi7bRBIO-W5r","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def output_layer(input):\n","    global compression\n","    BatchNorm = BatchNormalization()(input)\n","    relu = Activation('relu')(BatchNorm)\n","    AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n","    flat = Flatten()(AvgPooling)\n","    output = Dense(num_classes, activation='softmax')(flat)\n","    \n","    return output"],"execution_count":0,"outputs":[]},{"metadata":{"id":"H02bh-4P-XIO","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["num_filter = 64\n","dropout_rate = 0.3\n","l = 20\n","input = Input(shape=(img_height, img_width, channel,))\n","First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n","\n","First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n","First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n","\n","Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n","Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n","\n","Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n","Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n","\n","Last_Block = add_denseblock(Third_Transition,  num_filter, dropout_rate)\n","output = output_layer(Last_Block)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"A5RunYai-XYO","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":10545},"outputId":"f2d454e9-1ca5-4e7c-e9c6-70a345bf9f78","executionInfo":{"status":"ok","timestamp":1527523935405,"user_tz":-330,"elapsed":1167,"user":{"displayName":"pravallika datascience","photoUrl":"//lh5.googleusercontent.com/-kbOlHQuPOOc/AAAAAAAAAAI/AAAAAAAAAAc/-NbF7DfDFPE/s50-c-k-no/photo.jpg","userId":"114842818830057023722"}}},"cell_type":"code","source":["# Checkpoint is simply used for the model to save the weights if anf only if the validation accuracy is improved.\n","# Reduce_lr -> This callback is used for if there is no improvment seen for patience then we reduce the learning rate.\n","\n","from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\n","model = Model(inputs=[input], outputs=[output])\n","checkpoint=ModelCheckpoint(\"session4b.hdf5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max', period=1)\n","\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n","                              patience=2,verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0.001)\n","callbacks_list=[checkpoint, reduce_lr]\n","model.summary()"],"execution_count":11,"outputs":[{"output_type":"stream","text":["__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 32, 32, 64)   1728        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 32, 32, 64)   256         conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 32, 32, 64)   0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 32, 32, 32)   18432       activation_1[0][0]               \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 32, 32, 32)   0           conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 32, 32, 96)   0           conv2d_1[0][0]                   \n","                                                                 dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 32, 32, 96)   384         concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 32, 32, 96)   0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 32, 32, 32)   27648       activation_2[0][0]               \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 32, 32, 32)   0           conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 32, 32, 128)  0           concatenate_1[0][0]              \n","                                                                 dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 32, 32, 128)  512         concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 32, 32, 128)  0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 32, 32, 32)   36864       activation_3[0][0]               \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 32, 32, 32)   0           conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_3 (Concatenate)     (None, 32, 32, 160)  0           concatenate_2[0][0]              \n","                                                                 dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 32, 32, 160)  640         concatenate_3[0][0]              \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 32, 32, 160)  0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 32, 32, 32)   46080       activation_4[0][0]               \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 32, 32, 32)   0           conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_4 (Concatenate)     (None, 32, 32, 192)  0           concatenate_3[0][0]              \n","                                                                 dropout_4[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 32, 32, 192)  768         concatenate_4[0][0]              \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 32, 32, 192)  0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 32, 32, 32)   55296       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","dropout_5 (Dropout)             (None, 32, 32, 32)   0           conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_5 (Concatenate)     (None, 32, 32, 224)  0           concatenate_4[0][0]              \n","                                                                 dropout_5[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 32, 32, 224)  896         concatenate_5[0][0]              \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 32, 32, 224)  0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 32, 32, 32)   64512       activation_6[0][0]               \n","__________________________________________________________________________________________________\n","dropout_6 (Dropout)             (None, 32, 32, 32)   0           conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_6 (Concatenate)     (None, 32, 32, 256)  0           concatenate_5[0][0]              \n","                                                                 dropout_6[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 32, 32, 256)  1024        concatenate_6[0][0]              \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 32, 32, 256)  0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 32, 32, 32)   73728       activation_7[0][0]               \n","__________________________________________________________________________________________________\n","dropout_7 (Dropout)             (None, 32, 32, 32)   0           conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_7 (Concatenate)     (None, 32, 32, 288)  0           concatenate_6[0][0]              \n","                                                                 dropout_7[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 32, 32, 288)  1152        concatenate_7[0][0]              \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 32, 32, 288)  0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 32, 32, 32)   82944       activation_8[0][0]               \n","__________________________________________________________________________________________________\n","dropout_8 (Dropout)             (None, 32, 32, 32)   0           conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_8 (Concatenate)     (None, 32, 32, 320)  0           concatenate_7[0][0]              \n","                                                                 dropout_8[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 32, 32, 320)  1280        concatenate_8[0][0]              \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 32, 32, 320)  0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 32, 32, 32)   92160       activation_9[0][0]               \n","__________________________________________________________________________________________________\n","dropout_9 (Dropout)             (None, 32, 32, 32)   0           conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_9 (Concatenate)     (None, 32, 32, 352)  0           concatenate_8[0][0]              \n","                                                                 dropout_9[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 32, 32, 352)  1408        concatenate_9[0][0]              \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 32, 32, 352)  0           batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 32, 32, 32)   101376      activation_10[0][0]              \n","__________________________________________________________________________________________________\n","dropout_10 (Dropout)            (None, 32, 32, 32)   0           conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_10 (Concatenate)    (None, 32, 32, 384)  0           concatenate_9[0][0]              \n","                                                                 dropout_10[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 32, 32, 384)  1536        concatenate_10[0][0]             \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 32, 32, 384)  0           batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 32, 32, 32)   110592      activation_11[0][0]              \n","__________________________________________________________________________________________________\n","dropout_11 (Dropout)            (None, 32, 32, 32)   0           conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_11 (Concatenate)    (None, 32, 32, 416)  0           concatenate_10[0][0]             \n","                                                                 dropout_11[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 32, 32, 416)  1664        concatenate_11[0][0]             \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 32, 32, 416)  0           batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 32, 32, 32)   119808      activation_12[0][0]              \n","__________________________________________________________________________________________________\n","dropout_12 (Dropout)            (None, 32, 32, 32)   0           conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_12 (Concatenate)    (None, 32, 32, 448)  0           concatenate_11[0][0]             \n","                                                                 dropout_12[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 32, 32, 448)  1792        concatenate_12[0][0]             \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 32, 32, 448)  0           batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 32, 32, 32)   14336       activation_13[0][0]              \n","__________________________________________________________________________________________________\n","dropout_13 (Dropout)            (None, 32, 32, 32)   0           conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","average_pooling2d_1 (AveragePoo (None, 16, 16, 32)   0           dropout_13[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 16, 16, 32)   128         average_pooling2d_1[0][0]        \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 16, 16, 32)   0           batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 16, 16, 32)   9216        activation_14[0][0]              \n","__________________________________________________________________________________________________\n","dropout_14 (Dropout)            (None, 16, 16, 32)   0           conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_13 (Concatenate)    (None, 16, 16, 64)   0           average_pooling2d_1[0][0]        \n","                                                                 dropout_14[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 16, 16, 64)   256         concatenate_13[0][0]             \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 16, 16, 32)   18432       activation_15[0][0]              \n","__________________________________________________________________________________________________\n","dropout_15 (Dropout)            (None, 16, 16, 32)   0           conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_14 (Concatenate)    (None, 16, 16, 96)   0           concatenate_13[0][0]             \n","                                                                 dropout_15[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_16 (BatchNo (None, 16, 16, 96)   384         concatenate_14[0][0]             \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 16, 16, 32)   27648       activation_16[0][0]              \n","__________________________________________________________________________________________________\n","dropout_16 (Dropout)            (None, 16, 16, 32)   0           conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_15 (Concatenate)    (None, 16, 16, 128)  0           concatenate_14[0][0]             \n","                                                                 dropout_16[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_17 (BatchNo (None, 16, 16, 128)  512         concatenate_15[0][0]             \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 16, 16, 128)  0           batch_normalization_17[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 16, 16, 32)   36864       activation_17[0][0]              \n","__________________________________________________________________________________________________\n","dropout_17 (Dropout)            (None, 16, 16, 32)   0           conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_16 (Concatenate)    (None, 16, 16, 160)  0           concatenate_15[0][0]             \n","                                                                 dropout_17[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, 16, 16, 160)  640         concatenate_16[0][0]             \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 16, 16, 160)  0           batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 16, 16, 32)   46080       activation_18[0][0]              \n","__________________________________________________________________________________________________\n","dropout_18 (Dropout)            (None, 16, 16, 32)   0           conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_17 (Concatenate)    (None, 16, 16, 192)  0           concatenate_16[0][0]             \n","                                                                 dropout_18[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_19 (BatchNo (None, 16, 16, 192)  768         concatenate_17[0][0]             \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 16, 16, 192)  0           batch_normalization_19[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 16, 16, 32)   55296       activation_19[0][0]              \n","__________________________________________________________________________________________________\n","dropout_19 (Dropout)            (None, 16, 16, 32)   0           conv2d_20[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_18 (Concatenate)    (None, 16, 16, 224)  0           concatenate_17[0][0]             \n","                                                                 dropout_19[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_20 (BatchNo (None, 16, 16, 224)  896         concatenate_18[0][0]             \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 16, 16, 224)  0           batch_normalization_20[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 16, 16, 32)   64512       activation_20[0][0]              \n","__________________________________________________________________________________________________\n","dropout_20 (Dropout)            (None, 16, 16, 32)   0           conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_19 (Concatenate)    (None, 16, 16, 256)  0           concatenate_18[0][0]             \n","                                                                 dropout_20[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_21 (BatchNo (None, 16, 16, 256)  1024        concatenate_19[0][0]             \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 16, 16, 256)  0           batch_normalization_21[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 16, 16, 32)   73728       activation_21[0][0]              \n","__________________________________________________________________________________________________\n","dropout_21 (Dropout)            (None, 16, 16, 32)   0           conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_20 (Concatenate)    (None, 16, 16, 288)  0           concatenate_19[0][0]             \n","                                                                 dropout_21[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_22 (BatchNo (None, 16, 16, 288)  1152        concatenate_20[0][0]             \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 16, 16, 288)  0           batch_normalization_22[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 16, 16, 32)   82944       activation_22[0][0]              \n","__________________________________________________________________________________________________\n","dropout_22 (Dropout)            (None, 16, 16, 32)   0           conv2d_23[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_21 (Concatenate)    (None, 16, 16, 320)  0           concatenate_20[0][0]             \n","                                                                 dropout_22[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_23 (BatchNo (None, 16, 16, 320)  1280        concatenate_21[0][0]             \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 16, 16, 320)  0           batch_normalization_23[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 16, 16, 32)   92160       activation_23[0][0]              \n","__________________________________________________________________________________________________\n","dropout_23 (Dropout)            (None, 16, 16, 32)   0           conv2d_24[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_22 (Concatenate)    (None, 16, 16, 352)  0           concatenate_21[0][0]             \n","                                                                 dropout_23[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_24 (BatchNo (None, 16, 16, 352)  1408        concatenate_22[0][0]             \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 16, 16, 352)  0           batch_normalization_24[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 16, 16, 32)   101376      activation_24[0][0]              \n","__________________________________________________________________________________________________\n","dropout_24 (Dropout)            (None, 16, 16, 32)   0           conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_23 (Concatenate)    (None, 16, 16, 384)  0           concatenate_22[0][0]             \n","                                                                 dropout_24[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_25 (BatchNo (None, 16, 16, 384)  1536        concatenate_23[0][0]             \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 16, 16, 384)  0           batch_normalization_25[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 16, 16, 32)   110592      activation_25[0][0]              \n","__________________________________________________________________________________________________\n","dropout_25 (Dropout)            (None, 16, 16, 32)   0           conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_24 (Concatenate)    (None, 16, 16, 416)  0           concatenate_23[0][0]             \n","                                                                 dropout_25[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_26 (BatchNo (None, 16, 16, 416)  1664        concatenate_24[0][0]             \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 16, 16, 416)  0           batch_normalization_26[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 16, 16, 32)   13312       activation_26[0][0]              \n","__________________________________________________________________________________________________\n","dropout_26 (Dropout)            (None, 16, 16, 32)   0           conv2d_27[0][0]                  \n","__________________________________________________________________________________________________\n","average_pooling2d_2 (AveragePoo (None, 8, 8, 32)     0           dropout_26[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_27 (BatchNo (None, 8, 8, 32)     128         average_pooling2d_2[0][0]        \n","__________________________________________________________________________________________________\n","activation_27 (Activation)      (None, 8, 8, 32)     0           batch_normalization_27[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 8, 8, 32)     9216        activation_27[0][0]              \n","__________________________________________________________________________________________________\n","dropout_27 (Dropout)            (None, 8, 8, 32)     0           conv2d_28[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_25 (Concatenate)    (None, 8, 8, 64)     0           average_pooling2d_2[0][0]        \n","                                                                 dropout_27[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_28 (BatchNo (None, 8, 8, 64)     256         concatenate_25[0][0]             \n","__________________________________________________________________________________________________\n","activation_28 (Activation)      (None, 8, 8, 64)     0           batch_normalization_28[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 8, 8, 32)     18432       activation_28[0][0]              \n","__________________________________________________________________________________________________\n","dropout_28 (Dropout)            (None, 8, 8, 32)     0           conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_26 (Concatenate)    (None, 8, 8, 96)     0           concatenate_25[0][0]             \n","                                                                 dropout_28[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_29 (BatchNo (None, 8, 8, 96)     384         concatenate_26[0][0]             \n","__________________________________________________________________________________________________\n","activation_29 (Activation)      (None, 8, 8, 96)     0           batch_normalization_29[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, 8, 8, 32)     27648       activation_29[0][0]              \n","__________________________________________________________________________________________________\n","dropout_29 (Dropout)            (None, 8, 8, 32)     0           conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_27 (Concatenate)    (None, 8, 8, 128)    0           concatenate_26[0][0]             \n","                                                                 dropout_29[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_30 (BatchNo (None, 8, 8, 128)    512         concatenate_27[0][0]             \n","__________________________________________________________________________________________________\n","activation_30 (Activation)      (None, 8, 8, 128)    0           batch_normalization_30[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_31 (Conv2D)              (None, 8, 8, 32)     36864       activation_30[0][0]              \n","__________________________________________________________________________________________________\n","dropout_30 (Dropout)            (None, 8, 8, 32)     0           conv2d_31[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_28 (Concatenate)    (None, 8, 8, 160)    0           concatenate_27[0][0]             \n","                                                                 dropout_30[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_31 (BatchNo (None, 8, 8, 160)    640         concatenate_28[0][0]             \n","__________________________________________________________________________________________________\n","activation_31 (Activation)      (None, 8, 8, 160)    0           batch_normalization_31[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, 8, 8, 32)     46080       activation_31[0][0]              \n","__________________________________________________________________________________________________\n","dropout_31 (Dropout)            (None, 8, 8, 32)     0           conv2d_32[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_29 (Concatenate)    (None, 8, 8, 192)    0           concatenate_28[0][0]             \n","                                                                 dropout_31[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_32 (BatchNo (None, 8, 8, 192)    768         concatenate_29[0][0]             \n","__________________________________________________________________________________________________\n","activation_32 (Activation)      (None, 8, 8, 192)    0           batch_normalization_32[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 8, 8, 32)     55296       activation_32[0][0]              \n","__________________________________________________________________________________________________\n","dropout_32 (Dropout)            (None, 8, 8, 32)     0           conv2d_33[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_30 (Concatenate)    (None, 8, 8, 224)    0           concatenate_29[0][0]             \n","                                                                 dropout_32[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_33 (BatchNo (None, 8, 8, 224)    896         concatenate_30[0][0]             \n","__________________________________________________________________________________________________\n","activation_33 (Activation)      (None, 8, 8, 224)    0           batch_normalization_33[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 8, 8, 32)     64512       activation_33[0][0]              \n","__________________________________________________________________________________________________\n","dropout_33 (Dropout)            (None, 8, 8, 32)     0           conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_31 (Concatenate)    (None, 8, 8, 256)    0           concatenate_30[0][0]             \n","                                                                 dropout_33[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_34 (BatchNo (None, 8, 8, 256)    1024        concatenate_31[0][0]             \n","__________________________________________________________________________________________________\n","activation_34 (Activation)      (None, 8, 8, 256)    0           batch_normalization_34[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, 8, 8, 32)     73728       activation_34[0][0]              \n","__________________________________________________________________________________________________\n","dropout_34 (Dropout)            (None, 8, 8, 32)     0           conv2d_35[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_32 (Concatenate)    (None, 8, 8, 288)    0           concatenate_31[0][0]             \n","                                                                 dropout_34[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_35 (BatchNo (None, 8, 8, 288)    1152        concatenate_32[0][0]             \n","__________________________________________________________________________________________________\n","activation_35 (Activation)      (None, 8, 8, 288)    0           batch_normalization_35[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_36 (Conv2D)              (None, 8, 8, 32)     82944       activation_35[0][0]              \n","__________________________________________________________________________________________________\n","dropout_35 (Dropout)            (None, 8, 8, 32)     0           conv2d_36[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_33 (Concatenate)    (None, 8, 8, 320)    0           concatenate_32[0][0]             \n","                                                                 dropout_35[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_36 (BatchNo (None, 8, 8, 320)    1280        concatenate_33[0][0]             \n","__________________________________________________________________________________________________\n","activation_36 (Activation)      (None, 8, 8, 320)    0           batch_normalization_36[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_37 (Conv2D)              (None, 8, 8, 32)     92160       activation_36[0][0]              \n","__________________________________________________________________________________________________\n","dropout_36 (Dropout)            (None, 8, 8, 32)     0           conv2d_37[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_34 (Concatenate)    (None, 8, 8, 352)    0           concatenate_33[0][0]             \n","                                                                 dropout_36[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_37 (BatchNo (None, 8, 8, 352)    1408        concatenate_34[0][0]             \n","__________________________________________________________________________________________________\n","activation_37 (Activation)      (None, 8, 8, 352)    0           batch_normalization_37[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_38 (Conv2D)              (None, 8, 8, 32)     101376      activation_37[0][0]              \n","__________________________________________________________________________________________________\n","dropout_37 (Dropout)            (None, 8, 8, 32)     0           conv2d_38[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_35 (Concatenate)    (None, 8, 8, 384)    0           concatenate_34[0][0]             \n","                                                                 dropout_37[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_38 (BatchNo (None, 8, 8, 384)    1536        concatenate_35[0][0]             \n","__________________________________________________________________________________________________\n","activation_38 (Activation)      (None, 8, 8, 384)    0           batch_normalization_38[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_39 (Conv2D)              (None, 8, 8, 32)     110592      activation_38[0][0]              \n","__________________________________________________________________________________________________\n","dropout_38 (Dropout)            (None, 8, 8, 32)     0           conv2d_39[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_36 (Concatenate)    (None, 8, 8, 416)    0           concatenate_35[0][0]             \n","                                                                 dropout_38[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_39 (BatchNo (None, 8, 8, 416)    1664        concatenate_36[0][0]             \n","__________________________________________________________________________________________________\n","activation_39 (Activation)      (None, 8, 8, 416)    0           batch_normalization_39[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_40 (Conv2D)              (None, 8, 8, 32)     13312       activation_39[0][0]              \n","__________________________________________________________________________________________________\n","dropout_39 (Dropout)            (None, 8, 8, 32)     0           conv2d_40[0][0]                  \n","__________________________________________________________________________________________________\n","average_pooling2d_3 (AveragePoo (None, 4, 4, 32)     0           dropout_39[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_40 (BatchNo (None, 4, 4, 32)     128         average_pooling2d_3[0][0]        \n","__________________________________________________________________________________________________\n","activation_40 (Activation)      (None, 4, 4, 32)     0           batch_normalization_40[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_41 (Conv2D)              (None, 4, 4, 32)     9216        activation_40[0][0]              \n","__________________________________________________________________________________________________\n","dropout_40 (Dropout)            (None, 4, 4, 32)     0           conv2d_41[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_37 (Concatenate)    (None, 4, 4, 64)     0           average_pooling2d_3[0][0]        \n","                                                                 dropout_40[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_41 (BatchNo (None, 4, 4, 64)     256         concatenate_37[0][0]             \n","__________________________________________________________________________________________________\n","activation_41 (Activation)      (None, 4, 4, 64)     0           batch_normalization_41[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_42 (Conv2D)              (None, 4, 4, 32)     18432       activation_41[0][0]              \n","__________________________________________________________________________________________________\n","dropout_41 (Dropout)            (None, 4, 4, 32)     0           conv2d_42[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_38 (Concatenate)    (None, 4, 4, 96)     0           concatenate_37[0][0]             \n","                                                                 dropout_41[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_42 (BatchNo (None, 4, 4, 96)     384         concatenate_38[0][0]             \n","__________________________________________________________________________________________________\n","activation_42 (Activation)      (None, 4, 4, 96)     0           batch_normalization_42[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_43 (Conv2D)              (None, 4, 4, 32)     27648       activation_42[0][0]              \n","__________________________________________________________________________________________________\n","dropout_42 (Dropout)            (None, 4, 4, 32)     0           conv2d_43[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_39 (Concatenate)    (None, 4, 4, 128)    0           concatenate_38[0][0]             \n","                                                                 dropout_42[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_43 (BatchNo (None, 4, 4, 128)    512         concatenate_39[0][0]             \n","__________________________________________________________________________________________________\n","activation_43 (Activation)      (None, 4, 4, 128)    0           batch_normalization_43[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_44 (Conv2D)              (None, 4, 4, 32)     36864       activation_43[0][0]              \n","__________________________________________________________________________________________________\n","dropout_43 (Dropout)            (None, 4, 4, 32)     0           conv2d_44[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_40 (Concatenate)    (None, 4, 4, 160)    0           concatenate_39[0][0]             \n","                                                                 dropout_43[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_44 (BatchNo (None, 4, 4, 160)    640         concatenate_40[0][0]             \n","__________________________________________________________________________________________________\n","activation_44 (Activation)      (None, 4, 4, 160)    0           batch_normalization_44[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_45 (Conv2D)              (None, 4, 4, 32)     46080       activation_44[0][0]              \n","__________________________________________________________________________________________________\n","dropout_44 (Dropout)            (None, 4, 4, 32)     0           conv2d_45[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_41 (Concatenate)    (None, 4, 4, 192)    0           concatenate_40[0][0]             \n","                                                                 dropout_44[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_45 (BatchNo (None, 4, 4, 192)    768         concatenate_41[0][0]             \n","__________________________________________________________________________________________________\n","activation_45 (Activation)      (None, 4, 4, 192)    0           batch_normalization_45[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_46 (Conv2D)              (None, 4, 4, 32)     55296       activation_45[0][0]              \n","__________________________________________________________________________________________________\n","dropout_45 (Dropout)            (None, 4, 4, 32)     0           conv2d_46[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_42 (Concatenate)    (None, 4, 4, 224)    0           concatenate_41[0][0]             \n","                                                                 dropout_45[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_46 (BatchNo (None, 4, 4, 224)    896         concatenate_42[0][0]             \n","__________________________________________________________________________________________________\n","activation_46 (Activation)      (None, 4, 4, 224)    0           batch_normalization_46[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_47 (Conv2D)              (None, 4, 4, 32)     64512       activation_46[0][0]              \n","__________________________________________________________________________________________________\n","dropout_46 (Dropout)            (None, 4, 4, 32)     0           conv2d_47[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_43 (Concatenate)    (None, 4, 4, 256)    0           concatenate_42[0][0]             \n","                                                                 dropout_46[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_47 (BatchNo (None, 4, 4, 256)    1024        concatenate_43[0][0]             \n","__________________________________________________________________________________________________\n","activation_47 (Activation)      (None, 4, 4, 256)    0           batch_normalization_47[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_48 (Conv2D)              (None, 4, 4, 32)     73728       activation_47[0][0]              \n","__________________________________________________________________________________________________\n","dropout_47 (Dropout)            (None, 4, 4, 32)     0           conv2d_48[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_44 (Concatenate)    (None, 4, 4, 288)    0           concatenate_43[0][0]             \n","                                                                 dropout_47[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_48 (BatchNo (None, 4, 4, 288)    1152        concatenate_44[0][0]             \n","__________________________________________________________________________________________________\n","activation_48 (Activation)      (None, 4, 4, 288)    0           batch_normalization_48[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_49 (Conv2D)              (None, 4, 4, 32)     82944       activation_48[0][0]              \n","__________________________________________________________________________________________________\n","dropout_48 (Dropout)            (None, 4, 4, 32)     0           conv2d_49[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_45 (Concatenate)    (None, 4, 4, 320)    0           concatenate_44[0][0]             \n","                                                                 dropout_48[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_49 (BatchNo (None, 4, 4, 320)    1280        concatenate_45[0][0]             \n","__________________________________________________________________________________________________\n","activation_49 (Activation)      (None, 4, 4, 320)    0           batch_normalization_49[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_50 (Conv2D)              (None, 4, 4, 32)     92160       activation_49[0][0]              \n","__________________________________________________________________________________________________\n","dropout_49 (Dropout)            (None, 4, 4, 32)     0           conv2d_50[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_46 (Concatenate)    (None, 4, 4, 352)    0           concatenate_45[0][0]             \n","                                                                 dropout_49[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_50 (BatchNo (None, 4, 4, 352)    1408        concatenate_46[0][0]             \n","__________________________________________________________________________________________________\n","activation_50 (Activation)      (None, 4, 4, 352)    0           batch_normalization_50[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_51 (Conv2D)              (None, 4, 4, 32)     101376      activation_50[0][0]              \n","__________________________________________________________________________________________________\n","dropout_50 (Dropout)            (None, 4, 4, 32)     0           conv2d_51[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_47 (Concatenate)    (None, 4, 4, 384)    0           concatenate_46[0][0]             \n","                                                                 dropout_50[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_51 (BatchNo (None, 4, 4, 384)    1536        concatenate_47[0][0]             \n","__________________________________________________________________________________________________\n","activation_51 (Activation)      (None, 4, 4, 384)    0           batch_normalization_51[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_52 (Conv2D)              (None, 4, 4, 32)     110592      activation_51[0][0]              \n","__________________________________________________________________________________________________\n","dropout_51 (Dropout)            (None, 4, 4, 32)     0           conv2d_52[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_48 (Concatenate)    (None, 4, 4, 416)    0           concatenate_47[0][0]             \n","                                                                 dropout_51[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_52 (BatchNo (None, 4, 4, 416)    1664        concatenate_48[0][0]             \n","__________________________________________________________________________________________________\n","activation_52 (Activation)      (None, 4, 4, 416)    0           batch_normalization_52[0][0]     \n","__________________________________________________________________________________________________\n","average_pooling2d_4 (AveragePoo (None, 2, 2, 416)    0           activation_52[0][0]              \n","__________________________________________________________________________________________________\n","flatten_1 (Flatten)             (None, 1664)         0           average_pooling2d_4[0][0]        \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 10)           16650       flatten_1[0][0]                  \n","==================================================================================================\n","Total params: 3,093,578\n","Trainable params: 3,069,450\n","Non-trainable params: 24,128\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"22xqCH-PKckz","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["model.compile(loss='categorical_crossentropy',\n","              optimizer=Adam(),\n","              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Y1W_1UL3Krqc","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":437},"outputId":"ce3baf84-5166-4ecd-e924-06e41b64a112","executionInfo":{"status":"ok","timestamp":1527526343856,"user_tz":-330,"elapsed":2403943,"user":{"displayName":"pravallika datascience","photoUrl":"//lh5.googleusercontent.com/-kbOlHQuPOOc/AAAAAAAAAAI/AAAAAAAAAAc/-NbF7DfDFPE/s50-c-k-no/photo.jpg","userId":"114842818830057023722"}}},"cell_type":"code","source":["# Her I took the epochs in 5 intervals, so that I can understand how much the accuracy for interval and also easy to save the weights.\n","epoch = 0\n","epochs = 5\n","\n","model.fit(x_train, y_train,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    verbose=1,\n","                    initial_epoch=epoch,\n","                    callbacks=callbacks_list,\n","                    validation_data=(x_test, y_test))\n","\n","model.save_weights(\"DNST_model.h5\")\n","print(\"Saved model to disk\")"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Train on 50000 samples, validate on 10000 samples\n","Epoch 1/5\n","50000/50000 [==============================] - 495s 10ms/step - loss: 1.4454 - acc: 0.4681 - val_loss: 1.4745 - val_acc: 0.5066\n","\n","Epoch 00001: val_acc improved from -inf to 0.50660, saving model to session4b.hdf5\n","Epoch 2/5\n","14848/50000 [=======>......................] - ETA: 5:07 - loss: 1.0625 - acc: 0.6199"],"name":"stdout"},{"output_type":"stream","text":["50000/50000 [==============================] - 473s 9ms/step - loss: 0.9719 - acc: 0.6527 - val_loss: 1.2929 - val_acc: 0.6243\n","\n","Epoch 00002: val_acc improved from 0.50660 to 0.62430, saving model to session4b.hdf5\n","Epoch 3/5\n","31488/50000 [=================>............] - ETA: 2:41 - loss: 0.8109 - acc: 0.7116"],"name":"stdout"},{"output_type":"stream","text":["50000/50000 [==============================] - 471s 9ms/step - loss: 0.7920 - acc: 0.7187 - val_loss: 1.5926 - val_acc: 0.6043\n","\n","Epoch 00003: val_acc did not improve from 0.62430\n","Epoch 4/5\n","42752/50000 [========================>.....] - ETA: 1:02 - loss: 0.6926 - acc: 0.7568"],"name":"stdout"},{"output_type":"stream","text":["50000/50000 [==============================] - 470s 9ms/step - loss: 0.6886 - acc: 0.7586 - val_loss: 1.5738 - val_acc: 0.6271\n","\n","Epoch 00004: val_acc improved from 0.62430 to 0.62710, saving model to session4b.hdf5\n","Epoch 5/5\n","39168/50000 [======================>.......] - ETA: 1:34 - loss: 0.6124 - acc: 0.7841"],"name":"stdout"},{"output_type":"stream","text":["50000/50000 [==============================] - 470s 9ms/step - loss: 0.6132 - acc: 0.7845 - val_loss: 0.9002 - val_acc: 0.7380\n","\n","Epoch 00005: val_acc improved from 0.62710 to 0.73800, saving model to session4b.hdf5\n","Saved model to disk\n"],"name":"stdout"}]},{"metadata":{"id":"jgy-4o8vrCe_","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":437},"outputId":"84a23bf9-fafb-4d8c-b85b-7bf84ea2a4f7","executionInfo":{"status":"ok","timestamp":1527529496124,"user_tz":-330,"elapsed":2353711,"user":{"displayName":"pravallika datascience","photoUrl":"//lh5.googleusercontent.com/-kbOlHQuPOOc/AAAAAAAAAAI/AAAAAAAAAAc/-NbF7DfDFPE/s50-c-k-no/photo.jpg","userId":"114842818830057023722"}}},"cell_type":"code","source":["epoch = 5\n","epochs = 10\n","\n","model.fit(x_train, y_train,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    verbose=1,\n","                    initial_epoch=epoch,\n","                    callbacks=callbacks_list,\n","                    validation_data=(x_test, y_test))\n","\n","model.save_weights(\"DNST_model.h5\")\n","print(\"Saved model to disk\")"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Train on 50000 samples, validate on 10000 samples\n","Epoch 6/10\n","50000/50000 [==============================] - 470s 9ms/step - loss: 0.5024 - acc: 0.8255 - val_loss: 1.5512 - val_acc: 0.6467\n","\n","Epoch 00006: val_acc did not improve from 0.73800\n","Epoch 7/10\n","17280/50000 [=========>....................] - ETA: 4:44 - loss: 0.4567 - acc: 0.8413"],"name":"stdout"},{"output_type":"stream","text":["50000/50000 [==============================] - 470s 9ms/step - loss: 0.4594 - acc: 0.8400 - val_loss: 0.6155 - val_acc: 0.8183\n","\n","Epoch 00007: val_acc improved from 0.73800 to 0.81830, saving model to session4b.hdf5\n","Epoch 8/10\n","32000/50000 [==================>...........] - ETA: 2:36 - loss: 0.4319 - acc: 0.8497"],"name":"stdout"},{"output_type":"stream","text":["50000/50000 [==============================] - 470s 9ms/step - loss: 0.4347 - acc: 0.8485 - val_loss: 1.0611 - val_acc: 0.7365\n","\n","Epoch 00008: val_acc did not improve from 0.81830\n","Epoch 9/10\n","40960/50000 [=======================>......] - ETA: 1:18 - loss: 0.4048 - acc: 0.8582"],"name":"stdout"},{"output_type":"stream","text":["50000/50000 [==============================] - 470s 9ms/step - loss: 0.4074 - acc: 0.8575 - val_loss: 0.7519 - val_acc: 0.7766\n","\n","Epoch 00009: val_acc did not improve from 0.81830\n","Epoch 10/10\n","44544/50000 [=========================>....] - ETA: 47s - loss: 0.3790 - acc: 0.8677"],"name":"stdout"},{"output_type":"stream","text":["50000/50000 [==============================] - 470s 9ms/step - loss: 0.3784 - acc: 0.8682 - val_loss: 0.8494 - val_acc: 0.7873\n","\n","Epoch 00010: val_acc did not improve from 0.81830\n","Saved model to disk\n"],"name":"stdout"}]},{"metadata":{"id":"_0iymK912sq3","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":437},"outputId":"7a4a3622-bfeb-4048-cb57-23a3581bc9df","executionInfo":{"status":"ok","timestamp":1527536127855,"user_tz":-330,"elapsed":2364381,"user":{"displayName":"pravallika datascience","photoUrl":"//lh5.googleusercontent.com/-kbOlHQuPOOc/AAAAAAAAAAI/AAAAAAAAAAc/-NbF7DfDFPE/s50-c-k-no/photo.jpg","userId":"114842818830057023722"}}},"cell_type":"code","source":["epoch = 10\n","epochs = 15\n","\n","model.fit(x_train, y_train,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    verbose=1,\n","                    initial_epoch=epoch,\n","                    callbacks=callbacks_list,\n","                    validation_data=(x_test, y_test))\n","\n","\n","model.save_weights(\"DNST_model.h5\")\n","print(\"Saved model to disk\")"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Train on 50000 samples, validate on 10000 samples\n","Epoch 11/15\n","50000/50000 [==============================] - 472s 9ms/step - loss: 0.2252 - acc: 0.9198 - val_loss: 0.7850 - val_acc: 0.8172\n","\n","Epoch 00011: val_acc did not improve from 0.82540\n","Epoch 12/15\n","16000/50000 [========>.....................] - ETA: 4:57 - loss: 0.2028 - acc: 0.9277"],"name":"stdout"},{"output_type":"stream","text":["50000/50000 [==============================] - 473s 9ms/step - loss: 0.2095 - acc: 0.9248 - val_loss: 0.8026 - val_acc: 0.8208\n","\n","Epoch 00012: val_acc did not improve from 0.82540\n","Epoch 13/15\n","35840/50000 [====================>.........] - ETA: 2:03 - loss: 0.1985 - acc: 0.9292"],"name":"stdout"},{"output_type":"stream","text":["50000/50000 [==============================] - 471s 9ms/step - loss: 0.2035 - acc: 0.9276 - val_loss: 0.6616 - val_acc: 0.8481\n","\n","Epoch 00013: val_acc improved from 0.82540 to 0.84810, saving model to session4b.hdf5\n","Epoch 14/15\n","36992/50000 [=====================>........] - ETA: 1:53 - loss: 0.1886 - acc: 0.9331"],"name":"stdout"},{"output_type":"stream","text":["50000/50000 [==============================] - 472s 9ms/step - loss: 0.1900 - acc: 0.9321 - val_loss: 0.8569 - val_acc: 0.8184\n","\n","Epoch 00014: val_acc did not improve from 0.84810\n","Epoch 15/15\n","42368/50000 [========================>.....] - ETA: 1:06 - loss: 0.1883 - acc: 0.9337"],"name":"stdout"},{"output_type":"stream","text":["50000/50000 [==============================] - 473s 9ms/step - loss: 0.1892 - acc: 0.9335 - val_loss: 0.7166 - val_acc: 0.8369\n","\n","Epoch 00015: val_acc did not improve from 0.84810\n","Saved model to disk\n"],"name":"stdout"}]},{"metadata":{"id":"8wz_NgG62s7O","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":801},"outputId":"41b0bfce-2a63-40ad-b9a5-b62a5de395af","executionInfo":{"status":"ok","timestamp":1527548402770,"user_tz":-330,"elapsed":4684072,"user":{"displayName":"pravallika datascience","photoUrl":"//lh5.googleusercontent.com/-kbOlHQuPOOc/AAAAAAAAAAI/AAAAAAAAAAc/-NbF7DfDFPE/s50-c-k-no/photo.jpg","userId":"114842818830057023722"}}},"cell_type":"code","source":["# Here I changed the intervals of epoch to 10 intervals as there is no thst much of improve in the valiation accuracy.\n","epoch = 15\n","epochs = 25\n","\n","model.fit(x_train, y_train,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    verbose=1,\n","                    initial_epoch=epoch,\n","                    callbacks=callbacks_list,\n","                    validation_data=(x_test, y_test))\n","\n","model.save_weights(\"DNST_model.h5\")\n","print(\"Saved model to disk\")"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Train on 50000 samples, validate on 10000 samples\n","Epoch 16/25\n","50000/50000 [==============================] - 470s 9ms/step - loss: 0.0953 - acc: 0.9660 - val_loss: 0.6479 - val_acc: 0.8716\n","\n","Epoch 00016: val_acc improved from 0.86860 to 0.87160, saving model to session4b.hdf5\n","Epoch 17/25\n","14336/50000 [=======>......................] - ETA: 5:09 - loss: 0.0777 - acc: 0.9724"],"name":"stdout"},{"output_type":"stream","text":["50000/50000 [==============================] - 470s 9ms/step - loss: 0.0911 - acc: 0.9671 - val_loss: 0.8326 - val_acc: 0.8469\n","\n","Epoch 00017: val_acc did not improve from 0.87160\n","Epoch 18/25\n","35328/50000 [====================>.........] - ETA: 2:06 - loss: 0.0894 - acc: 0.9689"],"name":"stdout"},{"output_type":"stream","text":["50000/50000 [==============================] - 468s 9ms/step - loss: 0.0937 - acc: 0.9668 - val_loss: 0.5989 - val_acc: 0.8800\n","\n","Epoch 00018: val_acc improved from 0.87160 to 0.88000, saving model to session4b.hdf5\n","Epoch 19/25\n","36864/50000 [=====================>........] - ETA: 1:53 - loss: 0.0883 - acc: 0.9684"],"name":"stdout"},{"output_type":"stream","text":["50000/50000 [==============================] - 467s 9ms/step - loss: 0.0921 - acc: 0.9668 - val_loss: 0.9540 - val_acc: 0.8345\n","\n","Epoch 00019: val_acc did not improve from 0.88000\n","Epoch 20/25\n","42240/50000 [========================>.....] - ETA: 1:06 - loss: 0.0870 - acc: 0.9687"],"name":"stdout"},{"output_type":"stream","text":["50000/50000 [==============================] - 467s 9ms/step - loss: 0.0881 - acc: 0.9682 - val_loss: 0.6703 - val_acc: 0.8696\n","\n","Epoch 00020: val_acc did not improve from 0.88000\n","Epoch 21/25\n","43904/50000 [=========================>....] - ETA: 52s - loss: 0.0817 - acc: 0.9712"],"name":"stdout"},{"output_type":"stream","text":["50000/50000 [==============================] - 468s 9ms/step - loss: 0.0829 - acc: 0.9711 - val_loss: 0.6198 - val_acc: 0.8794\n","\n","Epoch 00021: val_acc did not improve from 0.88000\n","Epoch 22/25\n","44416/50000 [=========================>....] - ETA: 48s - loss: 0.0831 - acc: 0.9695"],"name":"stdout"},{"output_type":"stream","text":["50000/50000 [==============================] - 467s 9ms/step - loss: 0.0837 - acc: 0.9695 - val_loss: 0.8899 - val_acc: 0.8398\n","\n","Epoch 00022: val_acc did not improve from 0.88000\n","Epoch 23/25\n","44672/50000 [=========================>....] - ETA: 46s - loss: 0.0815 - acc: 0.9706"],"name":"stdout"},{"output_type":"stream","text":["50000/50000 [==============================] - 469s 9ms/step - loss: 0.0816 - acc: 0.9708 - val_loss: 0.6916 - val_acc: 0.8721\n","\n","Epoch 00023: val_acc did not improve from 0.88000\n","Epoch 24/25\n","44672/50000 [=========================>....] - ETA: 46s - loss: 0.0759 - acc: 0.9729"],"name":"stdout"},{"output_type":"stream","text":["50000/50000 [==============================] - 468s 9ms/step - loss: 0.0766 - acc: 0.9726 - val_loss: 0.6842 - val_acc: 0.8696\n","\n","Epoch 00024: val_acc did not improve from 0.88000\n","Epoch 25/25\n","44672/50000 [=========================>....] - ETA: 46s - loss: 0.0716 - acc: 0.9744"],"name":"stdout"},{"output_type":"stream","text":["50000/50000 [==============================] - 468s 9ms/step - loss: 0.0734 - acc: 0.9740 - val_loss: 0.6696 - val_acc: 0.8705\n","\n","Epoch 00025: val_acc did not improve from 0.88000\n","Saved model to disk\n"],"name":"stdout"}]},{"metadata":{"id":"jEcf7_JV-xTM","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":601},"outputId":"56c08a49-f622-4779-aad9-7db7d1f3105c"},"cell_type":"code","source":["epoch = 25\n","epochs = 35\n","\n","model.fit(x_train, y_train,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    verbose=1,\n","                    initial_epoch=epoch,\n","                    callbacks=callbacks_list,\n","                    validation_data=(x_test, y_test))\n","\n","model.save_weights(\"DNST_model.h5\")\n","print(\"Saved model to disk\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 50000 samples, validate on 10000 samples\n","Epoch 26/35\n","50000/50000 [==============================] - 468s 9ms/step - loss: 0.0792 - acc: 0.9715 - val_loss: 0.7675 - val_acc: 0.8583\n","\n","Epoch 00026: val_acc did not improve from 0.88000\n","Epoch 27/35\n","16000/50000 [========>.....................] - ETA: 4:54 - loss: 0.0725 - acc: 0.9744"],"name":"stdout"},{"output_type":"stream","text":["50000/50000 [==============================] - 468s 9ms/step - loss: 0.0720 - acc: 0.9746 - val_loss: 0.6649 - val_acc: 0.8738\n","\n","Epoch 00027: val_acc did not improve from 0.88000\n","Epoch 28/35\n","35840/50000 [====================>.........] - ETA: 2:02 - loss: 0.0700 - acc: 0.9758"],"name":"stdout"},{"output_type":"stream","text":["50000/50000 [==============================] - 468s 9ms/step - loss: 0.0708 - acc: 0.9751 - val_loss: 0.7961 - val_acc: 0.8551\n","\n","Epoch 00028: val_acc did not improve from 0.88000\n","Epoch 29/35\n","41984/50000 [========================>.....] - ETA: 1:09 - loss: 0.0697 - acc: 0.9751"],"name":"stdout"},{"output_type":"stream","text":["50000/50000 [==============================] - 468s 9ms/step - loss: 0.0700 - acc: 0.9752 - val_loss: 0.7623 - val_acc: 0.8552\n","\n","Epoch 00029: val_acc did not improve from 0.88000\n","Epoch 30/35\n","43904/50000 [=========================>....] - ETA: 52s - loss: 0.0695 - acc: 0.9751"],"name":"stdout"},{"output_type":"stream","text":["50000/50000 [==============================] - 468s 9ms/step - loss: 0.0688 - acc: 0.9753 - val_loss: 0.6317 - val_acc: 0.8810\n","\n","Epoch 00030: val_acc improved from 0.88000 to 0.88100, saving model to session4b.hdf5\n","Epoch 31/35\n","39168/50000 [======================>.......] - ETA: 1:33 - loss: 0.0638 - acc: 0.9774"],"name":"stdout"},{"output_type":"stream","text":["50000/50000 [==============================] - 468s 9ms/step - loss: 0.0643 - acc: 0.9772 - val_loss: 0.7407 - val_acc: 0.8746\n","\n","Epoch 00031: val_acc did not improve from 0.88100\n","Epoch 32/35\n","43008/50000 [========================>.....] - ETA: 1:00 - loss: 0.0700 - acc: 0.9757"],"name":"stdout"},{"output_type":"stream","text":["50000/50000 [==============================] - 468s 9ms/step - loss: 0.0700 - acc: 0.9754 - val_loss: 0.8077 - val_acc: 0.8675\n","\n","Epoch 00032: val_acc did not improve from 0.88100\n","Epoch 33/35\n","28544/50000 [================>.............] - ETA: 3:05 - loss: 0.0665 - acc: 0.9770"],"name":"stdout"}]},{"metadata":{"id":"B3-H-0ecDVyF","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# The network got disconnected and unable to run the epochs as the colab was crashing and I got the validation accuracy is 88.1.\n","# As there is no improvemetn during the epochs from 18 to 31 and it increased to 0.1 percent and I stopped running 33rd epoch."],"execution_count":0,"outputs":[]}]}